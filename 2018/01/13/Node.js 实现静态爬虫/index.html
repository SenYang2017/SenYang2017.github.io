<!DOCTYPE html>
<html lang="zh-CN">
  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta name="description" content="start from zero">
  <meta name="keywords" content="">
  
    <link rel="icon" href="/favicon.ico">
  
    
  <title>Node.js 实现静态爬虫 | inerdstack</title>
  <link rel="stylesheet" href="/style.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.20/jquery.fancybox.min.css" />
</head>

<body>
  <header>
  <div class="header-container">
    <a class='logo' href="/">
      <span>inerdstack</span>
    </a>
    <ul class="right-header">
      
        <li class="nav-item">
          
            <a href="/" class="item-link">首页</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/about" class="item-link">关于</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/archives" class="item-link">归档</a>
          
        </li>
      
        <li class="nav-item">
          
            <a href="/tags" class="item-link">标签</a>
          
        </li>
      
    </ul>
  </div>
</header>

  <main id='post'>
  <div class="content">
    <article>
        <section class="content markdown-body">
          <h1>Node.js 实现静态爬虫</h1>
          <div class='post-meta'>
            <i class="fa fa-calendar" aria-hidden="true"></i> <time>2018年01月13日</time>
            
            
          </div>
          <p>按照一定规则，自动抓取一些数据，是一种脚本(程序)，具体的体现是搜索引擎<a href="https://www.csdn.net/article/2015-11-13/2826205" target="_blank" rel="noopener">如果还想了解爬虫点击这里</a></p>
<p>爬虫是学习一门后端语言，所必备的技能之一。<br>那么为什么要选择利用node.js来写爬虫呢？就是因为cheerio这个库，全兼容jQuery语法，熟悉的话用起来真是爽</p>
<h2 id="依赖选择"><a href="#依赖选择" class="headerlink" title="依赖选择"></a>依赖选择</h2><p><a href="https://www.npmjs.com/package/cheerio" target="_blank" rel="noopener">cheerio:</a> Node.js 版的jQuery<br><a href="https://www.cnblogs.com/bukudekong/archive/2014/07/09/3834020.html" target="_blank" rel="noopener">request:</a> HTTP请求</p>
<h2 id="初步实现"><a href="#初步实现" class="headerlink" title="初步实现"></a>初步实现</h2><p>既然是要爬取网站内容，那我们就应该先去看看网站的基本构成</p>
<p>选取的是<a href="http://daily.zhihu.com/" target="_blank" rel="noopener">知乎日报</a>作为目标网站，想要去爬所有的图片</p>
<h3 id="分析页面"><a href="#分析页面" class="headerlink" title="分析页面"></a>分析页面</h3><p>页面结构如下<br><img src="/Users/dllo/Desktop/爬虫/03A26FFA-1E5E-4C66-B222-90E8B717CFE2.png" alt=""> </p>
<p><img src="/Users/dllo/Desktop/爬虫/AB94497B-D06D-45DD-AF9D-95BB28CD449E.png" alt=""> </p>
<h2 id="测试远程登录"><a href="#测试远程登录" class="headerlink" title="测试远程登录"></a>测试远程登录</h2><h3 id="可以先用HTTP请求一下信息，使用-Telnet"><a href="#可以先用HTTP请求一下信息，使用-Telnet" class="headerlink" title="可以先用HTTP请求一下信息，使用 Telnet"></a>可以先用HTTP请求一下信息，使用 Telnet</h3><pre><code>telnet daily.zhihu.com 80

GET http://daily.zhihu.com HTTP/1.1

Host: daily.zhihu.com
</code></pre><h3 id="测试成功-获取到网站信息"><a href="#测试成功-获取到网站信息" class="headerlink" title="测试成功,获取到网站信息"></a>测试成功,获取到网站信息</h3><p><img src="/Users/dllo/Desktop/爬虫/BCC5BE03-CA43-4FDD-9F46-76DFA0D72940.png" alt=""></p>
<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><h3 id="1-创建项目目录-static-spider-node-也可以手动创建文件夹"><a href="#1-创建项目目录-static-spider-node-也可以手动创建文件夹" class="headerlink" title="1.创建项目目录 static-spider-node(也可以手动创建文件夹)"></a>1.创建项目目录 static-spider-node(也可以手动创建文件夹)</h3><pre><code>mkdir static-spider-node 
</code></pre><h3 id="2-在环境中添加必要的依赖-request、cheerio-初始化-npm，生成-package-json"><a href="#2-在环境中添加必要的依赖-request、cheerio-初始化-npm，生成-package-json" class="headerlink" title="2.在环境中添加必要的依赖 request、cheerio 初始化 npm，生成 package.json"></a>2.在环境中添加必要的依赖 request、cheerio 初始化 npm，生成 package.json</h3><pre><code>npm init
</code></pre><p> 注意：<br> 1、初始化package.json的文件夹一定要是英文命名的，否则会报错<br> 2、在装一个类库之前，尽量要初始化package.json，这样别人才会知道你用的了哪些      </p>
<h3 id="添加依赖-request及-cheerio"><a href="#添加依赖-request及-cheerio" class="headerlink" title="添加依赖 request及 cheerio"></a>添加依赖 request及 cheerio</h3><pre><code>npm install --save request cheerio
</code></pre><h3 id="成功之后-package-json-会生成，证明依赖添加完成"><a href="#成功之后-package-json-会生成，证明依赖添加完成" class="headerlink" title="成功之后 package.json 会生成，证明依赖添加完成"></a>成功之后 package.json 会生成，证明依赖添加完成</h3><p> <img src="/Users/dllo/Desktop/爬虫/9904203C-6545-4002-8571-151B0F8926D1.png" alt=""></p>
<h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>环境搭建完成后，开始真正的爬虫内容的编写</p>
<p> 1.进入项目目录，在项目目录中，创建一个 static_spider_node.js</p>
<h3 id="2-在static-spider-node-js中编写如下代码，先引入我们需要的"><a href="#2-在static-spider-node-js中编写如下代码，先引入我们需要的" class="headerlink" title="2.在static_spider_node.js中编写如下代码，先引入我们需要的"></a>2.在static_spider_node.js中编写如下代码，先引入我们需要的</h3><pre><code> //引入request
 const request = require(&apos;request&apos;);  

 //引入node.js版的jq
 const cheerio = require(&apos;cheerio&apos;);

 //引入url   通过url解析
 const url  = require(&apos;url&apos;)

 //引入路径  通过路径生成一个名字
 const path = require(&apos;path&apos;);

//引入文件系统 ,因为我们要创建文件
 const fs   = require(&apos;fs&apos;)
</code></pre><h3 id="3-下面通过request-请求数据，获取首页的HTML代码"><a href="#3-下面通过request-请求数据，获取首页的HTML代码" class="headerlink" title="3.下面通过request 请求数据，获取首页的HTML代码"></a>3.下面通过request 请求数据，获取首页的HTML代码</h3><h3 id="接下来，依赖于-cheerio-对-HTML-进行解析来获取所有图片的src。"><a href="#接下来，依赖于-cheerio-对-HTML-进行解析来获取所有图片的src。" class="headerlink" title="接下来，依赖于 cheerio 对 HTML 进行解析来获取所有图片的src。"></a>接下来，依赖于 cheerio 对 HTML 进行解析来获取所有图片的src。</h3><pre><code>  //定义一个url（知乎日报的网址）
  let zhihuurl = &apos;http://daily.zhihu.com&apos;


    //get请求 参数1：url  参数2：回调函数
    //参数1：error(错误),参数2：可读流 参数3：数据 （我向知乎日报（服务器）发出请求）
    request.get(zhihuurl,(error,response,body)=&gt;{
              //如果error存在说明有错误
              if(error){
            console.error(error)
              return
     }

    // 使用cheerio的load方法加载body(数据)
     let  $ = cheerio.load(body)

      //创建一个数组用来装遍历的src
      let imgSrcArray = [];

       // each所有的img
   $(&apos;img&apos;).each((index,element) =&gt;{
    // 每一个img的src属性
    console.log($(element).attr(&apos;src&apos;))

    imgSrcArray.push($(element).attr(&apos;src&apos;))
})

   //注意：不要在Dom操作里做js相关的事 区分开两者
   //遍历装着src的数组
      imgSrcArray.forEach((src,index)=&gt;{
    //针对src进行解析
        let srcObj = url.parse(src)
    //生成一个新的路径  用path进行拼接
         let newImagePath = path.join(__dirname,&apos;image&apos;,srcObj.pathname)

         //request读src会返回response 通过流的方式导出去
         request(src).pipe(fs.createWriteStream(newImagePath))
})
</code></pre><p>})</p>
<h2 id="成功后文件夹里就会有我们download的图片了"><a href="#成功后文件夹里就会有我们download的图片了" class="headerlink" title="成功后文件夹里就会有我们download的图片了"></a>成功后文件夹里就会有我们download的图片了</h2><p><img src="/Users/dllo/Desktop/爬虫/53F842CF-C431-47DC-AF14-8458CDDC9FC2.png" alt=""></p>
<h3 id="注意：image文件夹是我手动创建"><a href="#注意：image文件夹是我手动创建" class="headerlink" title="注意：image文件夹是我手动创建"></a>注意：image文件夹是我手动创建</h3><h3 id="我们已经取到了全部的图片，那么我如果只想取我想要的图片那"><a href="#我们已经取到了全部的图片，那么我如果只想取我想要的图片那" class="headerlink" title="我们已经取到了全部的图片，那么我如果只想取我想要的图片那"></a>我们已经取到了全部的图片，那么我如果只想取我想要的图片那</h3><h3 id="我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片"><a href="#我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片" class="headerlink" title="我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片"></a>我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片</h3><p>例子：</p>
<pre><code>    // a标签的类名下的img
   $(&apos;.link-button img&apos;).each((index,element) =&gt;{
    // 每一个img的src属性
    console.log($(element).attr(&apos;src&apos;))
})
</code></pre>
        </section>
    </article>
    
        <!-- disqus 评论框 start -->
        <div class="comment">
            <div id="disqus_thread" class="disqus-thread">
              <i>加载评论框需要翻墙</i>
            </div>
        </div>
        <!-- disqus 评论框 end -->
    
    
        <!-- livere 评论框 start -->
        <div class="comment">
            <div id="lv-container" data-id="city" data-uid="your_livere_uid"></div>
        </div>
        <!-- livere 评论框 end -->
        
  </div>
  <aside>
    
    <div class="toc-container">
        <h1>目录</h1>
        <div class="content">
            <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#依赖选择"><span class="toc-number">1.</span> <span class="toc-text">依赖选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#初步实现"><span class="toc-number">2.</span> <span class="toc-text">初步实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#分析页面"><span class="toc-number">2.1.</span> <span class="toc-text">分析页面</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#测试远程登录"><span class="toc-number">3.</span> <span class="toc-text">测试远程登录</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#可以先用HTTP请求一下信息，使用-Telnet"><span class="toc-number">3.1.</span> <span class="toc-text">可以先用HTTP请求一下信息，使用 Telnet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#测试成功-获取到网站信息"><span class="toc-number">3.2.</span> <span class="toc-text">测试成功,获取到网站信息</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#环境搭建"><span class="toc-number">4.</span> <span class="toc-text">环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-创建项目目录-static-spider-node-也可以手动创建文件夹"><span class="toc-number">4.1.</span> <span class="toc-text">1.创建项目目录 static-spider-node(也可以手动创建文件夹)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-在环境中添加必要的依赖-request、cheerio-初始化-npm，生成-package-json"><span class="toc-number">4.2.</span> <span class="toc-text">2.在环境中添加必要的依赖 request、cheerio 初始化 npm，生成 package.json</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#添加依赖-request及-cheerio"><span class="toc-number">4.3.</span> <span class="toc-text">添加依赖 request及 cheerio</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#成功之后-package-json-会生成，证明依赖添加完成"><span class="toc-number">4.4.</span> <span class="toc-text">成功之后 package.json 会生成，证明依赖添加完成</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#实战"><span class="toc-number">5.</span> <span class="toc-text">实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-在static-spider-node-js中编写如下代码，先引入我们需要的"><span class="toc-number">5.1.</span> <span class="toc-text">2.在static_spider_node.js中编写如下代码，先引入我们需要的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-下面通过request-请求数据，获取首页的HTML代码"><span class="toc-number">5.2.</span> <span class="toc-text">3.下面通过request 请求数据，获取首页的HTML代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#接下来，依赖于-cheerio-对-HTML-进行解析来获取所有图片的src。"><span class="toc-number">5.3.</span> <span class="toc-text">接下来，依赖于 cheerio 对 HTML 进行解析来获取所有图片的src。</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#成功后文件夹里就会有我们download的图片了"><span class="toc-number">6.</span> <span class="toc-text">成功后文件夹里就会有我们download的图片了</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#注意：image文件夹是我手动创建"><span class="toc-number">6.1.</span> <span class="toc-text">注意：image文件夹是我手动创建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#我们已经取到了全部的图片，那么我如果只想取我想要的图片那"><span class="toc-number">6.2.</span> <span class="toc-text">我们已经取到了全部的图片，那么我如果只想取我想要的图片那</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片"><span class="toc-number">6.3.</span> <span class="toc-text">我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片</span></a></li></ol></li></ol>
        </div>
    </div>
    
  </aside>
</main>

<!-- disqus 公共JS代码 -->
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES * * */
  var disqus_shortname = "wangbo的博客";
  var disqus_identifier = "http://SenYang2017.github.io/2018/01/13/Node.js 实现静态爬虫/";
  var disqus_url = "http://SenYang2017.github.io/2018/01/13/Node.js 实现静态爬虫/";

  isAgent(getDisqus)

  // determine user agent in China
  function isAgent(cb) {
    var url = '//graph.facebook.com/feed?callback=h';
    var xhr = new XMLHttpRequest();
    var called = false;
    xhr.open('GET', url);
    xhr.onreadystatechange = function() {
      if (xhr.readyState === 4 && xhr.status === 200) {
      called = true;
      cb(true);
      }
    };
    xhr.send();
    // timeout 1s, this facebook API is very fast.
    setTimeout(function() {
      if (!called) {
      xhr.abort();
      cb(false)
      }
    }, 1000);
  }

  function getDisqus(isAgent) {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; 
    dsq.async = true
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq)
  }
</script>
<!-- disqus 公共JS代码 end -->


<script type="text/javascript">
  (function(d, s) {
      var j, e = d.getElementsByTagName(s)[0];

      if (typeof LivereTower === 'function') { return; }

      j = d.createElement(s);
      j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
      j.async = true;

      e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script>


  <footer>
  <div class="copyright">
    <div>
      &copy; 2018 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a>&nbsp
    </div>
    <div>
      Theme by <a href="https://github.com/lewis-geek/hexo-theme-Aath" target="_blank">Aath</a>
    </div>
  </div>
</footer>


<script src="https://cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script src="/lib/in-view.min.js"></script>
<script src="/lib/lodash.min.js"></script>
<script>
  var isDown = true
  var oldY = 0
  inView.offset(50)

  document.body.addEventListener('touchstart', function(){});
  
  window.addEventListener('scroll', _.throttle(e => {
    var currentY = window.scrollY
    if((oldY - currentY) < 0) {
      isDown = true
    } else {
      isDown = false
    }
    oldY = currentY
  }, 250))

  $("article img").each(function() {
      var strA = "<a data-fancybox='gallery' href='" + this.src + "'></a>";
      $(this).wrapAll(strA);
  });

  $('.toc-link').each(function() {
      var href = $(this).attr("href");
      
      inView(href).on('exit', () => {
        if (isDown) {
          handleActive(href)
        }
      })

      inView(href).on('enter', () => {
        if (!isDown) {
          handleActive(href)
        }
      })

      this.onclick = function(e) {
        var pos = $(href).offset().top - 10;
        $("html,body").animate({scrollTop: pos}, 300);
        setTimeout(() => {
          handleActive(href)
        }, 350)
        return false
      }
  })

  function handleActive(href) {
    document.querySelectorAll('.toc-link').forEach(elm => {
      elm.classList.remove('active')
    })
    document.querySelector(".toc [href='"+ href +"']").classList.add('active')
  }
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.1.20/jquery.fancybox.min.js"></script>


</body>
</html>
