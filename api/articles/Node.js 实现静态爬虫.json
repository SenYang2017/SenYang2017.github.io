{"title":"","slug":"Node.js 实现静态爬虫","date":"2018-01-13T06:04:31.000Z","updated":"2018-01-13T06:06:57.000Z","comments":true,"path":"api/articles/Node.js 实现静态爬虫.json","photos":[],"link":"","excerpt":null,"covers":["/Users/dllo/Desktop/爬虫/03A26FFA-1E5E-4C66-B222-90E8B717CFE2.png","/Users/dllo/Desktop/爬虫/AB94497B-D06D-45DD-AF9D-95BB28CD449E.png","/Users/dllo/Desktop/爬虫/BCC5BE03-CA43-4FDD-9F46-76DFA0D72940.png","/Users/dllo/Desktop/爬虫/9904203C-6545-4002-8571-151B0F8926D1.png","/Users/dllo/Desktop/爬虫/53F842CF-C431-47DC-AF14-8458CDDC9FC2.png"],"content":"<h1 id=\"Node-js-实现静态爬虫\"><a href=\"#Node-js-实现静态爬虫\" class=\"headerlink\" title=\"Node.js 实现静态爬虫\"></a>Node.js 实现静态爬虫</h1><p>按照一定规则，自动抓取一些数据，是一种脚本(程序)，具体的体现是搜索引擎<a href=\"https://www.csdn.net/article/2015-11-13/2826205\" target=\"_blank\" rel=\"noopener\">如果还想了解爬虫点击这里</a></p>\n<p>爬虫是学习一门后端语言，所必备的技能之一。<br>那么为什么要选择利用node.js来写爬虫呢？就是因为cheerio这个库，全兼容jQuery语法，熟悉的话用起来真是爽</p>\n<h2 id=\"依赖选择\"><a href=\"#依赖选择\" class=\"headerlink\" title=\"依赖选择\"></a>依赖选择</h2><p><a href=\"https://www.npmjs.com/package/cheerio\" target=\"_blank\" rel=\"noopener\">cheerio:</a> Node.js 版的jQuery<br><a href=\"https://www.cnblogs.com/bukudekong/archive/2014/07/09/3834020.html\" target=\"_blank\" rel=\"noopener\">request:</a> HTTP请求</p>\n<h2 id=\"初步实现\"><a href=\"#初步实现\" class=\"headerlink\" title=\"初步实现\"></a>初步实现</h2><p>既然是要爬取网站内容，那我们就应该先去看看网站的基本构成</p>\n<p>选取的是<a href=\"http://daily.zhihu.com/\" target=\"_blank\" rel=\"noopener\">知乎日报</a>作为目标网站，想要去爬所有的图片</p>\n<h3 id=\"分析页面\"><a href=\"#分析页面\" class=\"headerlink\" title=\"分析页面\"></a>分析页面</h3><p>页面结构如下<br><img src=\"/Users/dllo/Desktop/爬虫/03A26FFA-1E5E-4C66-B222-90E8B717CFE2.png\" alt=\"\"> </p>\n<p><img src=\"/Users/dllo/Desktop/爬虫/AB94497B-D06D-45DD-AF9D-95BB28CD449E.png\" alt=\"\"> </p>\n<h2 id=\"测试远程登录\"><a href=\"#测试远程登录\" class=\"headerlink\" title=\"测试远程登录\"></a>测试远程登录</h2><h3 id=\"可以先用HTTP请求一下信息，使用-Telnet\"><a href=\"#可以先用HTTP请求一下信息，使用-Telnet\" class=\"headerlink\" title=\"可以先用HTTP请求一下信息，使用 Telnet\"></a>可以先用HTTP请求一下信息，使用 Telnet</h3><pre><code>telnet daily.zhihu.com 80\n\nGET http://daily.zhihu.com HTTP/1.1\n\nHost: daily.zhihu.com\n</code></pre><h3 id=\"测试成功-获取到网站信息\"><a href=\"#测试成功-获取到网站信息\" class=\"headerlink\" title=\"测试成功,获取到网站信息\"></a>测试成功,获取到网站信息</h3><p><img src=\"/Users/dllo/Desktop/爬虫/BCC5BE03-CA43-4FDD-9F46-76DFA0D72940.png\" alt=\"\"></p>\n<h2 id=\"环境搭建\"><a href=\"#环境搭建\" class=\"headerlink\" title=\"环境搭建\"></a>环境搭建</h2><h3 id=\"1-创建项目目录-static-spider-node-也可以手动创建文件夹\"><a href=\"#1-创建项目目录-static-spider-node-也可以手动创建文件夹\" class=\"headerlink\" title=\"1.创建项目目录 static-spider-node(也可以手动创建文件夹)\"></a>1.创建项目目录 static-spider-node(也可以手动创建文件夹)</h3><pre><code>mkdir static-spider-node \n</code></pre><h3 id=\"2-在环境中添加必要的依赖-request、cheerio-初始化-npm，生成-package-json\"><a href=\"#2-在环境中添加必要的依赖-request、cheerio-初始化-npm，生成-package-json\" class=\"headerlink\" title=\"2.在环境中添加必要的依赖 request、cheerio 初始化 npm，生成 package.json\"></a>2.在环境中添加必要的依赖 request、cheerio 初始化 npm，生成 package.json</h3><pre><code>npm init\n</code></pre><p> 注意：<br> 1、初始化package.json的文件夹一定要是英文命名的，否则会报错<br> 2、在装一个类库之前，尽量要初始化package.json，这样别人才会知道你用的了哪些      </p>\n<h3 id=\"添加依赖-request及-cheerio\"><a href=\"#添加依赖-request及-cheerio\" class=\"headerlink\" title=\"添加依赖 request及 cheerio\"></a>添加依赖 request及 cheerio</h3><pre><code>npm install --save request cheerio\n</code></pre><h3 id=\"成功之后-package-json-会生成，证明依赖添加完成\"><a href=\"#成功之后-package-json-会生成，证明依赖添加完成\" class=\"headerlink\" title=\"成功之后 package.json 会生成，证明依赖添加完成\"></a>成功之后 package.json 会生成，证明依赖添加完成</h3><p> <img src=\"/Users/dllo/Desktop/爬虫/9904203C-6545-4002-8571-151B0F8926D1.png\" alt=\"\"></p>\n<h2 id=\"实战\"><a href=\"#实战\" class=\"headerlink\" title=\"实战\"></a>实战</h2><p>环境搭建完成后，开始真正的爬虫内容的编写</p>\n<p> 1.进入项目目录，在项目目录中，创建一个 static_spider_node.js</p>\n<h3 id=\"2-在static-spider-node-js中编写如下代码，先引入我们需要的\"><a href=\"#2-在static-spider-node-js中编写如下代码，先引入我们需要的\" class=\"headerlink\" title=\"2.在static_spider_node.js中编写如下代码，先引入我们需要的\"></a>2.在static_spider_node.js中编写如下代码，先引入我们需要的</h3><pre><code> //引入request\n const request = require(&apos;request&apos;);  \n\n //引入node.js版的jq\n const cheerio = require(&apos;cheerio&apos;);\n\n //引入url   通过url解析\n const url  = require(&apos;url&apos;)\n\n //引入路径  通过路径生成一个名字\n const path = require(&apos;path&apos;);\n\n//引入文件系统 ,因为我们要创建文件\n const fs   = require(&apos;fs&apos;)\n</code></pre><h3 id=\"3-下面通过request-请求数据，获取首页的HTML代码\"><a href=\"#3-下面通过request-请求数据，获取首页的HTML代码\" class=\"headerlink\" title=\"3.下面通过request 请求数据，获取首页的HTML代码\"></a>3.下面通过request 请求数据，获取首页的HTML代码</h3><h3 id=\"接下来，依赖于-cheerio-对-HTML-进行解析来获取所有图片的src。\"><a href=\"#接下来，依赖于-cheerio-对-HTML-进行解析来获取所有图片的src。\" class=\"headerlink\" title=\"接下来，依赖于 cheerio 对 HTML 进行解析来获取所有图片的src。\"></a>接下来，依赖于 cheerio 对 HTML 进行解析来获取所有图片的src。</h3><pre><code>  //定义一个url（知乎日报的网址）\n  let zhihuurl = &apos;http://daily.zhihu.com&apos;\n\n\n    //get请求 参数1：url  参数2：回调函数\n    //参数1：error(错误),参数2：可读流 参数3：数据 （我向知乎日报（服务器）发出请求）\n    request.get(zhihuurl,(error,response,body)=&gt;{\n              //如果error存在说明有错误\n              if(error){\n            console.error(error)\n              return\n     }\n\n    // 使用cheerio的load方法加载body(数据)\n     let  $ = cheerio.load(body)\n\n      //创建一个数组用来装遍历的src\n      let imgSrcArray = [];\n\n       // each所有的img\n   $(&apos;img&apos;).each((index,element) =&gt;{\n    // 每一个img的src属性\n    console.log($(element).attr(&apos;src&apos;))\n\n    imgSrcArray.push($(element).attr(&apos;src&apos;))\n})\n\n   //注意：不要在Dom操作里做js相关的事 区分开两者\n   //遍历装着src的数组\n      imgSrcArray.forEach((src,index)=&gt;{\n    //针对src进行解析\n        let srcObj = url.parse(src)\n    //生成一个新的路径  用path进行拼接\n         let newImagePath = path.join(__dirname,&apos;image&apos;,srcObj.pathname)\n\n         //request读src会返回response 通过流的方式导出去\n         request(src).pipe(fs.createWriteStream(newImagePath))\n})\n</code></pre><p>})</p>\n<h2 id=\"成功后文件夹里就会有我们download的图片了\"><a href=\"#成功后文件夹里就会有我们download的图片了\" class=\"headerlink\" title=\"成功后文件夹里就会有我们download的图片了\"></a>成功后文件夹里就会有我们download的图片了</h2><p><img src=\"/Users/dllo/Desktop/爬虫/53F842CF-C431-47DC-AF14-8458CDDC9FC2.png\" alt=\"\"></p>\n<h3 id=\"注意：image文件夹是我手动创建\"><a href=\"#注意：image文件夹是我手动创建\" class=\"headerlink\" title=\"注意：image文件夹是我手动创建\"></a>注意：image文件夹是我手动创建</h3><h3 id=\"我们已经取到了全部的图片，那么我如果只想取我想要的图片那\"><a href=\"#我们已经取到了全部的图片，那么我如果只想取我想要的图片那\" class=\"headerlink\" title=\"我们已经取到了全部的图片，那么我如果只想取我想要的图片那\"></a>我们已经取到了全部的图片，那么我如果只想取我想要的图片那</h3><h3 id=\"我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片\"><a href=\"#我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片\" class=\"headerlink\" title=\"我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片\"></a>我们可以在知乎日报的HTML代码中我们找到包含img标签的类名来进行选择那些图片</h3><p>例子：</p>\n<pre><code>    // a标签的类名下的img\n   $(&apos;.link-button img&apos;).each((index,element) =&gt;{\n    // 每一个img的src属性\n    console.log($(element).attr(&apos;src&apos;))\n})\n</code></pre>","categories":[],"tags":[]}